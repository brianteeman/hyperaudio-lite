WEBVTT

00:00:00.000 --> 00:00:02.000

How do we make people more aware of their personal data?

00:00:04.470 --> 00:00:07.720
We have two selves in the world at 
any given time now. 

00:00:08.490 --> 00:00:13.290
We have the physical self, 
our flesh and blood, our voice, 

00:00:13.860 --> 00:00:18.450
our presence in the world which 
extends beyond our bodies but lives 

00:00:18.450 --> 00:00:19.590
in this physical space. 

00:00:20.560 --> 00:00:23.640
There's this other space, 
we started calling cyberspace a long 

00:00:23.640 --> 00:00:25.080
time ago, but it's a real thing. 

00:00:25.770 --> 00:00:26.720
It's a data space.


00:00:26.940 --> 00:00:32.009
We are as people quite often data 
illiterate. 

00:00:32.850 --> 00:00:35.730
We don't realise the impact of what 
data has on our lives, 

00:00:35.760 --> 00:00:39.900
we don't realise what we're giving 
away and we don't realise the 

00:00:39.900 --> 00:00:44.587
mechanisms that will enable us to 
re-empower ourselves in this 

00:00:44.587 --> 00:00:44.669
environment.

00:00:45.060 --> 00:00:48.420
Security and privacy, 
they are issues â€“people do care 

00:00:48.420 --> 00:00:52.170
about them and we need to, 
we should address them.

00:00:52.890 --> 00:00:55.560
I think unfortunately at the minute 
we make people aware of their 

00:00:55.560 --> 00:00:57.870
personal data when terrible things 
happen.

00:00:58.500 --> 00:01:02.100
It's going to take personal 
experiences of falling over, 

00:01:04.260 --> 00:01:08.010
some kind of truly horrific 
experience before people actually 

00:01:08.010 --> 00:01:11.400
feel that they are compelled to be 
educated about this.

00:01:11.500 --> 00:01:13.200
And I think there's two pieces of 
data. 

00:01:13.230 --> 00:01:17.400
People feel very strongly about, 
one is health care and the other one 

00:01:17.400 --> 00:01:18.000
is banking. 

00:01:18.660 --> 00:01:23.790
So if you touch those two areas, 
the reaction is extremely strong 

00:01:23.790 --> 00:01:30.000
because they feel that it sort of 
touches something that they should 

00:01:30.000 --> 00:01:31.320
be in complete control of.

00:01:31.680 --> 00:01:36.480
The Internet is manmade and 
everything you put online is 

00:01:36.480 --> 00:01:37.200
recoverable. 

00:01:38.160 --> 00:01:41.670
There are world-class security experts, 
but there are still people who are 

00:01:41.670 --> 00:01:43.590
stealing money from bank accounts.

00:01:43.710 --> 00:01:48.690
As technologists we we have a duty 
to try to explain these things to 

00:01:48.690 --> 00:01:52.860
people and to try to get across, 
you know, find ways to make it real 

00:01:52.860 --> 00:01:59.310
and make it make sense and we need 
more examples and better education.

00:01:59.460 --> 00:02:05.080
We need to create a more informed 
debate about data, especially the 

00:02:05.070 --> 00:02:06.050
value of data. 

00:02:06.390 --> 00:02:10.699
The value of data as individuals and 
the value of data aggregated.

00:02:11.000 --> 00:02:13.000

What are the disadvantages of managing your own data?

00:02:15.060 --> 00:02:19.290
Right now there's more talk than 
ever about owning your own data, 

00:02:21.860 --> 00:02:25.530
because there are so many companies 
out there that are gathering data 

00:02:25.530 --> 00:02:29.520
about us, that we don't own at all, 
that we don't control at all.

00:02:29.850 --> 00:02:34.830
So if we're trying to manage your 
own data, one of the problems with 

00:02:34.830 --> 00:02:38.580
this is you don't necessarily know 
what data you're giving to other 

00:02:38.580 --> 00:02:38.880
people. 

00:02:39.030 --> 00:02:43.050
So lacking information and lacking 
in any way of finding out that 

00:02:43.050 --> 00:02:43.740
information.

00:02:44.010 --> 00:02:47.250
So I actually want it to be in the 
hands of agencies that are going to 

00:02:47.250 --> 00:02:52.200
do good with that that can maybe use 
my data in comparison to millions of 

00:02:52.200 --> 00:02:56.190
other people's data to find trends, 
or to find specifics about me. 

00:02:56.940 --> 00:03:00.000
So yeah we needed it to be out there 
in order to make it work, 

00:03:01.500 --> 00:03:04.560
and that's where the tension comes 
in because as soon as I agree for it 

00:03:04.560 --> 00:03:08.700
to be out there, and allow it to be 
worked on it's a bit like having a 

00:03:08.700 --> 00:03:12.960
house party when I was seventeen and said, 
everybody's welcome. 

00:03:13.460 --> 00:03:20.840
Well they were until it got a bit 
out of hand and you know with that 

00:03:20.930 --> 00:03:21.380
story goes.

00:03:21.630 --> 00:03:27.870
I think that, I think that there are 
very few people who are willing to 

00:03:27.870 --> 00:03:32.780
sacrifice as much as it would 
actually take me to not be monitored 

00:03:32.880 --> 00:03:34.200
and surveilled at all.

00:03:34.800 --> 00:03:36.800

What kind of help is available for people to manage their own data?

00:03:38.730 --> 00:03:44.010
We need to move the debate beyond a 
discussion about what it can be in a 

00:03:44.010 --> 00:03:49.760
commercial realm into activity in 
the ordinary domestic role.

00:03:50.100 --> 00:03:56.460
I think we should be educating 
people about data through building 

00:03:56.460 --> 00:04:00.900
partnerships with the companies who 
are involved in selling those 

00:04:00.900 --> 00:04:01.590
products.

00:04:02.190 --> 00:04:07.920
I think we already have a middleman 
for open data in an institution 

00:04:07.920 --> 00:04:12.420
that's been recently created the 
Open Data Institute, co-founded by 

00:04:12.630 --> 00:04:16.200
Tim Berners-Lee and Gavin Starkson, 
there's some fantastic people that 

00:04:17.320 --> 00:04:19.350
created an accreditation system.

00:04:19.800 --> 00:04:23.250
What's going to happen in the long 
run is that people will have control 

00:04:23.250 --> 00:04:25.830
over their personal data because 
they'll know better what to do with 

00:04:25.830 --> 00:04:31.740
it and the tools will exist for them 
to do more with it, with that data 

00:04:31.770 --> 00:04:33.180
than these other companies could. 

00:04:34.070 --> 00:04:36.360
It's just like it was with personal 
computing.

00:04:36.590 --> 00:04:43.430
and when you kind of mobilize a 
world task force of paper geeks you 

00:04:43.440 --> 00:04:44.370
like making stuff.

00:04:44.760 --> 00:04:49.080
I don't think we need technology 
businesses to sit there and vouch 

00:04:49.080 --> 00:04:52.440
for people's data. 

00:04:53.020 --> 00:04:58.080
That seems to me an old way of doing things, 
I think an open source approach with 

00:04:58.470 --> 00:05:03.750
five-star accreditation from the ODI 
seems a good way forward.

00:05:04.260 --> 00:05:09.900
The trap not to fall into is the 
trap of fear right now, 

00:05:09.990 --> 00:05:13.260
and we're at a high point of fear 
thanks to Edward Snowden, 

00:05:13.650 --> 00:05:18.330
thanks to discovering what the NSA 
and the US has been doing, 

00:05:18.330 --> 00:05:20.130
and what GCHQ here has been doing.

00:05:20.370 --> 00:05:25.175
If you can build a sneaky feature 
into a device, and you decide not to 

00:05:25.175 --> 00:05:28.190
tell the user you decide to kind of 
break the law a bit, certainly in 

00:05:28.190 --> 00:05:31.110
data protection terms, 
theres a real risk that it will get 

00:05:31.110 --> 00:05:31.650
found out.

00:05:31.920 --> 00:05:35.650
This is a power we can use for good 
or evil and probably both, 

00:05:36.360 --> 00:05:40.440
but we, it's present in the world 
now and we have to figure out how to 

00:05:40.440 --> 00:05:40.750
use it.